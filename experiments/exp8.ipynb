{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85f93c2",
   "metadata": {},
   "source": [
    "# Experiment 8\n",
    "___\n",
    "Compare the models SVM , decision tree , random forest and xgboost by tuning their hyperparameters using gridsearchCV\n",
    "\n",
    "## Steps:\n",
    "1. Load Dataset\n",
    "2. Preprocess the data\n",
    "3. Split Data\n",
    "4. Define Hyperparameter grid\n",
    "- f1_estimators : [50,100,200]\n",
    "- max_depth : [None, 10, 20, 30]\n",
    "- min_samples_split: [2,5,10]\n",
    "- min_samples_leaf: [1,2,4]\n",
    "5. Perform grid search: Use GridSearchCV with cv=5\n",
    "6. Train and evaluate: Asess performance on the test set\n",
    "7. Report results: Print the best parameneters and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"heart.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"johnsmith88/heart-disease-dataset\",\n",
    "    file_path,\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 records:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Step 3: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Step 4: Define Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "\n",
    "# SVM hyperparameters\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Decision Tree hyperparameters\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grids defined successfully!\")\n",
    "print(\"\\nSVM parameters:\", list(svm_param_grid.keys()))\n",
    "print(\"Decision Tree parameters:\", list(dt_param_grid.keys()))\n",
    "print(\"Random Forest parameters:\", list(rf_param_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Step 5 & 6: Perform Grid Search and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON WITH GRIDSEARCHCV\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### SVM with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"1. SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize SVM\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform Grid Search\n",
    "svm_grid = GridSearchCV(\n",
    "    svm, \n",
    "    svm_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on scaled data (SVM requires scaling)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_pred = svm_grid.predict(X_test_scaled)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "# Store results\n",
    "results['SVM'] = {\n",
    "    'best_params': svm_grid.best_params_,\n",
    "    'best_cv_score': svm_grid.best_score_,\n",
    "    'test_accuracy': svm_accuracy\n",
    "}\n",
    "\n",
    "print(f\"\\nBest Parameters: {svm_grid.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {svm_grid.best_score_:.4f}\")\n",
    "print(f\"Test Accuracy: {svm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Decision Tree with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. DECISION TREE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search\n",
    "dt_grid = GridSearchCV(\n",
    "    dt, \n",
    "    dt_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on original data (Decision trees don't require scaling)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_pred = dt_grid.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# Store results\n",
    "results['Decision Tree'] = {\n",
    "    'best_params': dt_grid.best_params_,\n",
    "    'best_cv_score': dt_grid.best_score_,\n",
    "    'test_accuracy': dt_accuracy\n",
    "}\n",
    "\n",
    "print(f\"\\nBest Parameters: {dt_grid.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {dt_grid.best_score_:.4f}\")\n",
    "print(f\"Test Accuracy: {dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Random Forest with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, \n",
    "    rf_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on original data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_grid.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Store results\n",
    "results['Random Forest'] = {\n",
    "    'best_params': rf_grid.best_params_,\n",
    "    'best_cv_score': rf_grid.best_score_,\n",
    "    'test_accuracy': rf_accuracy\n",
    "}\n",
    "\n",
    "print(f\"\\nBest Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {rf_grid.best_score_:.4f}\")\n",
    "print(f\"Test Accuracy: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    # XGBoost hyperparameters\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Initialize XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    \n",
    "    # Perform Grid Search\n",
    "    xgb_grid = GridSearchCV(\n",
    "        xgb_model, \n",
    "        xgb_param_grid, \n",
    "        cv=5, \n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit on original data\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    xgb_pred = xgb_grid.predict(X_test)\n",
    "    xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results['XGBoost'] = {\n",
    "        'best_params': xgb_grid.best_params_,\n",
    "        'best_cv_score': xgb_grid.best_score_,\n",
    "        'test_accuracy': xgb_accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nBest Parameters: {xgb_grid.best_params_}\")\n",
    "    print(f\"Best CV Accuracy: {xgb_grid.best_score_:.4f}\")\n",
    "    print(f\"Test Accuracy: {xgb_accuracy:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\nXGBoost not installed. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    print(\"Please restart the kernel and run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Step 7: Report Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_data = []\n",
    "for model_name, result in results.items():\n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Best CV Score': f\"{result['best_cv_score']:.4f}\",\n",
    "        'Test Accuracy': f\"{result['test_accuracy']:.4f}\",\n",
    "        'Best Parameters': str(result['best_params'])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model = max(results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"BEST MODEL: {best_model[0]}\")\n",
    "print(f\"Test Accuracy: {best_model[1]['test_accuracy']:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "models = list(results.keys())\n",
    "cv_scores = [results[model]['best_cv_score'] for model in models]\n",
    "test_scores = [results[model]['test_accuracy'] for model in models]\n",
    "\n",
    "# Plot 1: Cross-Validation Scores\n",
    "axes[0].bar(models, cv_scores, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "axes[0].set_title('Best Cross-Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim(0, 1)\n",
    "for i, v in enumerate(cv_scores):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Test Accuracy\n",
    "axes[1].bar(models, test_scores, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "axes[1].set_title('Test Set Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_ylim(0, 1)\n",
    "for i, v in enumerate(test_scores):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Detailed Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed classification reports\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "predictions = {\n",
    "    'SVM': svm_pred,\n",
    "    'Decision Tree': dt_pred,\n",
    "    'Random Forest': rf_pred\n",
    "}\n",
    "\n",
    "if 'XGBoost' in results:\n",
    "    predictions['XGBoost'] = xgb_pred\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
